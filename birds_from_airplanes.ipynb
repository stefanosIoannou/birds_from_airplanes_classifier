{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "birds_from_airplanes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "045e1d28a15b403594f2d1827f12203b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de3a6edadfa947b0baa3866fac26c401",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7952a02adb8046d1821aa3fb92a3c0ec",
              "IPY_MODEL_765152c0fb044d8a8e394ef433bef6f1"
            ]
          }
        },
        "de3a6edadfa947b0baa3866fac26c401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7952a02adb8046d1821aa3fb92a3c0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11b5ce7aaa844abcbe807faa7ab0177f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66eddb5bd01a4af68b3db23b537497ba"
          }
        },
        "765152c0fb044d8a8e394ef433bef6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43816a464ac0498f86c33d663c74c43e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:06&lt;00:00, 24721596.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddece87e83064060955898b033be6546"
          }
        },
        "11b5ce7aaa844abcbe807faa7ab0177f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66eddb5bd01a4af68b3db23b537497ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43816a464ac0498f86c33d663c74c43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddece87e83064060955898b033be6546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noWQM0QrCf6m"
      },
      "source": [
        "# Distinguishing Birds from Airplanes using the CIFAR10 dataset\n",
        "- A simple classifier to distinguish birds from airplanes using the CIFAR10 dataset using mainly Pytorch\n",
        "- Hyperparameter tuning has been done only for the learning rate and the regularisation factor (momentum will be done later)\n",
        "- Optimizer: Adam with default parameters\n",
        "- Testing was done using the CIFAR10 test_dataset, but only using accuracy as a metric. Recall, Precision and F1 score should also be done since this is a classifier\n",
        "- Readings have been plotted using **TensorBoard**\n",
        "- Saved models can be found under [Models](models)\n",
        "- The project has been created to show familiarity with the framework and basic concepts of deep learning, for an interview I had last year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-2TkC4BnHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d22b98-f945-431f-fec8-590f0370ce27"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import tensor\r\n",
        "from torch import optim\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "import PIL\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "import datetime\r\n",
        "import time\r\n",
        "import random\r\n",
        "import math\r\n",
        "\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Import CIFAR\r\n",
        "from torchvision import datasets\r\n",
        "\r\n",
        "# Tensorboard\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "import torch.utils.tensorboard\r\n",
        "\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xJE1iknMogn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d780f52-9459-47b3-af0c-f2d5a4ac359d"
      },
      "source": [
        "# Device\r\n",
        "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\r\n",
        "print(f\"Training on the device {device}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on the device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35NY1w5KEqat",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "045e1d28a15b403594f2d1827f12203b",
            "de3a6edadfa947b0baa3866fac26c401",
            "7952a02adb8046d1821aa3fb92a3c0ec",
            "765152c0fb044d8a8e394ef433bef6f1",
            "11b5ce7aaa844abcbe807faa7ab0177f",
            "66eddb5bd01a4af68b3db23b537497ba",
            "43816a464ac0498f86c33d663c74c43e",
            "ddece87e83064060955898b033be6546"
          ]
        },
        "outputId": "7c2874ec-0f0b-4291-8b1f-fe2c61f4481f"
      },
      "source": [
        "data_path = '../data-unversioned/p1ch7'\r\n",
        "cifar10 = datasets.CIFAR10(data_path, train= True,download=True, transform= transforms.ToTensor())\r\n",
        "cifar10_val = datasets.CIFAR10(data_path,train=False, download= True, transform= transforms.ToTensor())\r\n",
        "\r\n",
        "# Building the dataset:\r\n",
        "# Birds will be 1, Airplanes will be 0\r\n",
        "label_map = {0: 0, 2: 1}\r\n",
        "cifar2 = [(img, label_map[label]) for img, label, in cifar10 if label in label_map.keys()]\r\n",
        "cifar2_val = [(img, label_map[label]) for img, label, in cifar10_val if label in label_map.keys()]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "045e1d28a15b403594f2d1827f12203b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data-unversioned/p1ch7/cifar-10-python.tar.gz to ../data-unversioned/p1ch7\n",
            "Files already downloaded and verified\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c1VY2G8W0hp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "1ee8a299-1645-4843-bd71-923e2bdf17f4"
      },
      "source": [
        "# Image visualisation\r\n",
        "plt.imshow(cifar2[3][0].permute(1,2,0))\r\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vDDFBDmH3x-"
      },
      "source": [
        "# Model\r\n",
        "class BirdAirplaneClassifier(nn.Module):\r\n",
        "  def __init__(self, n_chans=32):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chans = n_chans\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chans, kernel_size=3, padding=1)\r\n",
        "    self.batch_norm1 = nn.BatchNorm2d(n_chans)\r\n",
        "    self.conv2 = nn.Conv2d(n_chans, n_chans // 2, kernel_size = 3, padding=1)\r\n",
        "    self.batch_norm2 = nn.BatchNorm2d(n_chans // 2 )\r\n",
        "    self.fc1 = nn.Linear(8 * 8 * n_chans // 2, 32)\r\n",
        "    self.fc2 = nn.Linear(32, 2)\r\n",
        "    self.activation = torch.tanh\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = self.batch_norm1(self.conv1(x))\r\n",
        "    out = F.max_pool2d(self.activation(out), 2)\r\n",
        "    out = self.batch_norm2(self.conv2(out))\r\n",
        "    out = F.max_pool2d(self.activation(out), 2)\r\n",
        "\r\n",
        "    out = out.view (-1, 8 * 8 * self.n_chans // 2)\r\n",
        "    out = self.activation(self.fc1(out))\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70gtnEJVyQq5"
      },
      "source": [
        "# Calculate Accuracy\r\n",
        "def accuracy(model, train_loader, val_loader, loss_fn, epoch, writer=None):\r\n",
        "  to_return = \"\"\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    val_acc = 0\r\n",
        "    train_acc = 0\r\n",
        "\r\n",
        "    for name, loader in [(\"train\",train_loader), (\"val\", val_loader)]:\r\n",
        "      for imgs, labels in loader:\r\n",
        "        imgs = imgs.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        #  Calculate accuracy\r\n",
        "        outputs = model(imgs)\r\n",
        "        _, predicted = torch.max(outputs, dim=1)\r\n",
        "        total += labels.shape[0]\r\n",
        "        correct += int((predicted == labels).sum())\r\n",
        "\r\n",
        "      if name == \"train\":\r\n",
        "        train_acc = correct/total\r\n",
        "      else:\r\n",
        "        val_acc = correct/total\r\n",
        "\r\n",
        "    # Write\r\n",
        "    if writer != None:\r\n",
        "      writer.add_scalars(\"Acc\",{\"train_acc\":train_acc,\r\n",
        "                                \"val_acc\": val_acc},epoch)\r\n",
        "      \r\n",
        "    return {\"train_acc\": train_acc, \"val_acc\": val_acc}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDlU9Jgvn5Kw"
      },
      "source": [
        "# Main Training Routine\r\n",
        "# Tuning: Plot training and validation loss and accuracy under hparams\r\n",
        "def train(epochs, optimizer, model, loss_fn, train_loader, val_loader, print_int = 10, writer=None, tuning=False):\r\n",
        "  model = model.to(device)\r\n",
        "\r\n",
        "  for epoch in range(1, epochs + 1):\r\n",
        "    loss_train = 0.0\r\n",
        "    loss_val = 0.0\r\n",
        "    acc_metric = {}\r\n",
        "\r\n",
        "    for imgs, labels in train_loader:\r\n",
        "      imgs = imgs.to(device)\r\n",
        "      labels = labels.to(device)\r\n",
        "\r\n",
        "      predictions = model(imgs)\r\n",
        "      loss = loss_fn(predictions, labels) \r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "      # Training Loss\r\n",
        "      loss_train += loss.item()\r\n",
        "\r\n",
        "    # Validation Loss\r\n",
        "    with torch.no_grad():\r\n",
        "      for imgs, labels in val_loader:\r\n",
        "        imgs = imgs.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        predictions = model(imgs)\r\n",
        "        loss_val += loss_fn(predictions, labels).item()\r\n",
        "      assert torch.no_grad()\r\n",
        "\r\n",
        "    acc_str =''\r\n",
        "    if epoch == 1 or epoch % print_int == 0:\r\n",
        "      acc_metric = accuracy(model, train_loader, val_loader, loss_fn, epoch, writer)\r\n",
        "\r\n",
        "      for key in acc_metric.keys():\r\n",
        "        acc_str += f\"{key}: {acc_metric[key]:.2f} \"\r\n",
        "\r\n",
        "      to_print = f\"{datetime.datetime.now()} Epoch {epoch}/{epochs}, cost: {loss_train/len(train_loader)}, val_loss: {loss_val/len(val_loader)}, {acc_str}\"\r\n",
        "      print(to_print)\r\n",
        "\r\n",
        "    if writer != None:\r\n",
        "      writer.add_scalars('Loss', {\"train\": loss_train,\r\n",
        "                                  \"val\": loss_val}, epoch)\r\n",
        "      writer.flush()\r\n",
        "\r\n",
        "  # For hyperparameter tuning\r\n",
        "  if tuning:\r\n",
        "    dir = \"hparam\"\r\n",
        "    return {f\"{dir}/train_loss\": loss_train, \r\n",
        "            f\"{dir}/val_loss\": loss_val, \r\n",
        "            f\"{dir}/train_acc\": acc_metric[\"train_acc\"], \r\n",
        "            f\"{dir}/val_acc\": acc_metric[\"val_acc\"] }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIHLrFDbg-ze"
      },
      "source": [
        "# Babysitting the Learning Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l3wFHR0Lg4q"
      },
      "source": [
        "# Ensure the model is sain, by overfitting\r\n",
        "# Use small dataset with many epochs\r\n",
        "# Regularisation is set to 0\r\n",
        "def overfit_model():\r\n",
        "  s_train_loader = DataLoader(cifar2[:20]);\r\n",
        "  s_val_loader = DataLoader(cifar2_val[:20])\r\n",
        "  model = BirdAirplaneClassifier()\r\n",
        "  loss_fn = nn.CrossEntropyLoss()\r\n",
        "  learning_rate = 1e-4\r\n",
        "\r\n",
        "  optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0)\r\n",
        "\r\n",
        "  train(\r\n",
        "      epochs=200,\r\n",
        "      optimizer = optimizer,\r\n",
        "      model = model,\r\n",
        "      loss_fn = loss_fn,\r\n",
        "      train_loader = s_train_loader,\r\n",
        "      val_loader = s_val_loader,\r\n",
        "      writer = SummaryWriter(\"runs/Babysitting\")\r\n",
        "  )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E7WrL9q-7Qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0855fc-0f75-43c3-a2bd-8d1d59f436ff"
      },
      "source": [
        "overfit_model()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-20 09:10:07.674633 Epoch 1/200, cost: 0.6584489181637764, val_loss: 0.7630436033010483, train_acc: 0.70 val_acc: 0.57 \n",
            "2021-02-20 09:10:08.419853 Epoch 10/200, cost: 0.1841941699385643, val_loss: 0.7692034102976322, train_acc: 1.00 val_acc: 0.80 \n",
            "2021-02-20 09:10:09.254293 Epoch 20/200, cost: 0.06003859108313918, val_loss: 0.8139997318387031, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:10.077567 Epoch 30/200, cost: 0.02842796463519335, val_loss: 0.8673792693763971, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:10.907506 Epoch 40/200, cost: 0.016830308153294025, val_loss: 0.9148067591711879, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:11.738144 Epoch 50/200, cost: 0.011263304855674505, val_loss: 0.9581077796407044, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:12.563403 Epoch 60/200, cost: 0.008124795265030117, val_loss: 0.9969926822930575, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:13.393543 Epoch 70/200, cost: 0.006156454107258469, val_loss: 1.0325919520109892, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:14.217334 Epoch 80/200, cost: 0.004830456722993403, val_loss: 1.0666449125856161, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:15.042235 Epoch 90/200, cost: 0.0038886311231181026, val_loss: 1.098871324909851, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:15.868707 Epoch 100/200, cost: 0.00319134482415393, val_loss: 1.128885098407045, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:16.690668 Epoch 110/200, cost: 0.0026594890863634647, val_loss: 1.1584345505107194, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:17.510264 Epoch 120/200, cost: 0.002243999816710129, val_loss: 1.1866343987174333, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:18.339814 Epoch 130/200, cost: 0.0019124428799841553, val_loss: 1.2144145723665134, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:19.154222 Epoch 140/200, cost: 0.0016433073295047506, val_loss: 1.240894011128694, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:20.017984 Epoch 150/200, cost: 0.0014217880147043616, val_loss: 1.2667010316625238, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:20.828764 Epoch 160/200, cost: 0.0012372170691378414, val_loss: 1.2921811639796943, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:21.651451 Epoch 170/200, cost: 0.0010820261435583235, val_loss: 1.316767414426431, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:22.475096 Epoch 180/200, cost: 0.0009503710927674547, val_loss: 1.3409255059435963, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:23.303630 Epoch 190/200, cost: 0.0008378314087167382, val_loss: 1.3647735689766705, train_acc: 1.00 val_acc: 0.82 \n",
            "2021-02-20 09:10:24.124025 Epoch 200/200, cost: 0.0007410133563098498, val_loss: 1.3884677247609942, train_acc: 1.00 val_acc: 0.82 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTb3XJhjQ9Xh"
      },
      "source": [
        "# Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkH0I4IE7Hc"
      },
      "source": [
        "# Specifications for training\r\n",
        "train_loader = DataLoader(cifar2, batch_size=64, shuffle= True)\r\n",
        "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle= False)\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "n_epochs = 100"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLNW8llASr43"
      },
      "source": [
        "# Run training routin given a learning rate (lr) and regularisation factor (reg)\r\n",
        "def lr_reg_optimizer(lr, reg):\r\n",
        "  model = BirdAirplaneClassifier()\r\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\r\n",
        "  \r\n",
        "  hparam = {\"lr\": lr, \"reg\": reg}\r\n",
        "\r\n",
        "  print(f\"Lr: {lr} Reg: {reg}\")\r\n",
        "  metrics = train(\r\n",
        "    epochs=10,\r\n",
        "    optimizer=optimizer,\r\n",
        "    model= model,\r\n",
        "    loss_fn=loss_fn,\r\n",
        "    train_loader = train_loader,\r\n",
        "    val_loader = val_loader,\r\n",
        "    print_int = 10,\r\n",
        "    writer = None,\r\n",
        "    tuning=True)\r\n",
        "  \r\n",
        "  return (hparam, metrics)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIxytXNhRJy8"
      },
      "source": [
        "# Run training routine given a range of learning rates and regularisation routines\r\n",
        "# Values are chosen at random \r\n",
        "def run_tuning(epochs, lr_s=(-5,5), reg_s=(-3,-6)):\r\n",
        "  writer = SummaryWriter(\"runs/lr_reg\")\r\n",
        "  for count in range(epochs+1):\r\n",
        "    lr = 10**random.uniform(*lr_s)\r\n",
        "    reg = 10**random.uniform(*reg_s)\r\n",
        "\r\n",
        "    print(f\"({count}/{epochs})\")\r\n",
        "    logs = lr_reg_optimizer(lr=lr, reg=reg)\r\n",
        "    writer.add_hparams(*logs)\r\n",
        "\r\n",
        "  writer.flush()\r\n",
        "  writer.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLganfVF8GwZ",
        "outputId": "0af1f480-9965-4a38-83ba-64ed784cf8af"
      },
      "source": [
        "run_tuning(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0/100)\n",
            "Lr: 0.567650998256617 Reg: 7.867857491013543e-05\n",
            "2021-02-15 18:34:22.031222 Epoch 1/10, cost: 1.5850265979007552, val_loss: 1.4219716414809227, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:34:28.225759 Epoch 10/10, cost: 2.505877216150806, val_loss: 1.6791978105902672, train_acc: 0.50 val_acc: 0.50 \n",
            "(1/100)\n",
            "Lr: 338.84331668899966 Reg: 2.956386119840249e-06\n",
            "2021-02-15 18:34:29.243472 Epoch 1/10, cost: 2521.866651170952, val_loss: 2188.830005645752, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:34:35.611080 Epoch 10/10, cost: 1219.375194074242, val_loss: 2047.9346199035645, train_acc: 0.50 val_acc: 0.50 \n",
            "(2/100)\n",
            "Lr: 5.3833282862544176e-05 Reg: 6.891993922103995e-05\n",
            "2021-02-15 18:34:36.654628 Epoch 1/10, cost: 0.5016464205684176, val_loss: 0.43754862900823355, train_acc: 0.80 val_acc: 0.81 \n",
            "2021-02-15 18:34:42.897589 Epoch 10/10, cost: 0.2921809824598823, val_loss: 0.30974658858031034, train_acc: 0.88 val_acc: 0.87 \n",
            "(3/100)\n",
            "Lr: 804.3093785686747 Reg: 0.00021259860531624273\n",
            "2021-02-15 18:34:43.808237 Epoch 1/10, cost: 3277.911600680108, val_loss: 636.8741073608398, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:34:49.994940 Epoch 10/10, cost: 1536.935015599439, val_loss: 2997.574722290039, train_acc: 0.50 val_acc: 0.50 \n",
            "(4/100)\n",
            "Lr: 0.1132425786699526 Reg: 1.694003163948513e-05\n",
            "2021-02-15 18:34:50.913366 Epoch 1/10, cost: 0.6455338578315297, val_loss: 0.5980275850743055, train_acc: 0.71 val_acc: 0.71 \n",
            "2021-02-15 18:34:57.180440 Epoch 10/10, cost: 0.6725236699459659, val_loss: 1.2440959326922894, train_acc: 0.50 val_acc: 0.50 \n",
            "(5/100)\n",
            "Lr: 0.0011863451313585249 Reg: 1.0551623925714385e-05\n",
            "2021-02-15 18:34:58.169789 Epoch 1/10, cost: 0.3847683229643828, val_loss: 0.3604329484514892, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:35:04.409590 Epoch 10/10, cost: 0.1444802801510331, val_loss: 0.27145057125017047, train_acc: 0.96 val_acc: 0.95 \n",
            "(6/100)\n",
            "Lr: 11735.088068665813 Reg: 8.984580499175019e-06\n",
            "2021-02-15 18:35:05.373778 Epoch 1/10, cost: 73735.08065128516, val_loss: 147379.08935546875, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:35:11.892043 Epoch 10/10, cost: 44406.46361031502, val_loss: 1205.0013637542725, train_acc: 0.50 val_acc: 0.50 \n",
            "(7/100)\n",
            "Lr: 0.0009512557877174212 Reg: 1.5012922647053019e-05\n",
            "2021-02-15 18:35:12.925604 Epoch 1/10, cost: 0.38861022225231123, val_loss: 0.33268827432766557, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 18:35:19.186772 Epoch 10/10, cost: 0.14892225491867703, val_loss: 0.25945935677737, train_acc: 0.95 val_acc: 0.94 \n",
            "(8/100)\n",
            "Lr: 0.006466578830049609 Reg: 0.0008653073368941267\n",
            "2021-02-15 18:35:20.108040 Epoch 1/10, cost: 0.39844665073665086, val_loss: 0.3618501564487815, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:35:26.344232 Epoch 10/10, cost: 0.2765305347408459, val_loss: 0.2715906575322151, train_acc: 0.90 val_acc: 0.90 \n",
            "(9/100)\n",
            "Lr: 0.666205105920507 Reg: 0.0006131844723621817\n",
            "2021-02-15 18:35:27.296104 Epoch 1/10, cost: 2.1990055476024652, val_loss: 6.517769917845726, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:35:33.735142 Epoch 10/10, cost: 2.3335777919763214, val_loss: 2.8416086360812187, train_acc: 0.50 val_acc: 0.50 \n",
            "(10/100)\n",
            "Lr: 3.484155681462274e-05 Reg: 5.14690881971572e-06\n",
            "2021-02-15 18:35:34.662466 Epoch 1/10, cost: 0.535810983294894, val_loss: 0.46224905643612146, train_acc: 0.78 val_acc: 0.79 \n",
            "2021-02-15 18:35:40.757209 Epoch 10/10, cost: 0.31328238755654375, val_loss: 0.3233996918424964, train_acc: 0.87 val_acc: 0.87 \n",
            "(11/100)\n",
            "Lr: 887.2967576857836 Reg: 6.0950442405606036e-05\n",
            "2021-02-15 18:35:41.844926 Epoch 1/10, cost: 4447.049241799078, val_loss: 2861.541046142578, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:35:48.133960 Epoch 10/10, cost: 2280.192497459946, val_loss: 3616.078842163086, train_acc: 0.50 val_acc: 0.50 \n",
            "(12/100)\n",
            "Lr: 94.3215439171496 Reg: 1.0571312943736244e-05\n",
            "2021-02-15 18:35:49.045185 Epoch 1/10, cost: 1204.8107743756786, val_loss: 2075.176944732666, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:35:55.595535 Epoch 10/10, cost: 330.10235671025174, val_loss: 180.47524309158325, train_acc: 0.50 val_acc: 0.50 \n",
            "(13/100)\n",
            "Lr: 0.00014869343865991333 Reg: 4.654437019986571e-05\n",
            "2021-02-15 18:35:56.664092 Epoch 1/10, cost: 0.43081915359588185, val_loss: 0.3617813130840659, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 18:36:02.769889 Epoch 10/10, cost: 0.2377454931284212, val_loss: 0.2712394534610212, train_acc: 0.91 val_acc: 0.91 \n",
            "(14/100)\n",
            "Lr: 4921.2250528161585 Reg: 0.0005901874154124587\n",
            "2021-02-15 18:36:03.669699 Epoch 1/10, cost: 4453.327157070303, val_loss: 6226.972351074219, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:36:10.038912 Epoch 10/10, cost: 4818.7772764947, val_loss: 4821.2353591918945, train_acc: 0.50 val_acc: 0.50 \n",
            "(15/100)\n",
            "Lr: 0.0005592965077581986 Reg: 0.00011730506365654442\n",
            "2021-02-15 18:36:10.969261 Epoch 1/10, cost: 0.3954798299226032, val_loss: 0.357196188531816, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:36:17.588926 Epoch 10/10, cost: 0.16900979357350404, val_loss: 0.2540722731500864, train_acc: 0.94 val_acc: 0.94 \n",
            "(16/100)\n",
            "Lr: 0.01223653909329529 Reg: 3.0518034414360515e-06\n",
            "2021-02-15 18:36:18.534760 Epoch 1/10, cost: 0.5096415719788545, val_loss: 0.4226250806823373, train_acc: 0.79 val_acc: 0.80 \n",
            "2021-02-15 18:36:24.615212 Epoch 10/10, cost: 0.34176710456799547, val_loss: 0.337619898840785, train_acc: 0.86 val_acc: 0.86 \n",
            "(17/100)\n",
            "Lr: 557.1571971248303 Reg: 0.0005170605258169605\n",
            "2021-02-15 18:36:25.651742 Epoch 1/10, cost: 2134.8565898886914, val_loss: 424.13792610168457, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:36:32.267087 Epoch 10/10, cost: 979.832652972762, val_loss: 694.4613647460938, train_acc: 0.50 val_acc: 0.50 \n",
            "(18/100)\n",
            "Lr: 13566.010546181118 Reg: 2.2084976065052697e-06\n",
            "2021-02-15 18:36:33.194496 Epoch 1/10, cost: 120375.48100446782, val_loss: 63224.72009277344, train_acc: 0.57 val_acc: 0.57 \n",
            "2021-02-15 18:36:39.431787 Epoch 10/10, cost: 69411.29613480295, val_loss: 50722.68310546875, train_acc: 0.50 val_acc: 0.50 \n",
            "(19/100)\n",
            "Lr: 1.756252307113869 Reg: 0.0007102199880005284\n",
            "2021-02-15 18:36:40.481327 Epoch 1/10, cost: 7.87552984315119, val_loss: 9.845564216375351, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:36:46.676645 Epoch 10/10, cost: 4.77326009417795, val_loss: 1.7987300716340542, train_acc: 0.50 val_acc: 0.50 \n",
            "(20/100)\n",
            "Lr: 10418.641162379483 Reg: 1.651708064451192e-05\n",
            "2021-02-15 18:36:47.617718 Epoch 1/10, cost: 40012.590928923935, val_loss: 65054.64196777344, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:36:53.852270 Epoch 10/10, cost: 32676.674431478903, val_loss: 2832.227439880371, train_acc: 0.50 val_acc: 0.50 \n",
            "(21/100)\n",
            "Lr: 48713.82053345921 Reg: 1.5327529213946815e-05\n",
            "2021-02-15 18:36:54.759269 Epoch 1/10, cost: 109017.29288824083, val_loss: 119308.54370117188, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:37:01.277959 Epoch 10/10, cost: 106904.701171875, val_loss: 217020.92236328125, train_acc: 0.50 val_acc: 0.50 \n",
            "(22/100)\n",
            "Lr: 1.836879707662741 Reg: 1.5216876414072662e-05\n",
            "2021-02-15 18:37:02.282648 Epoch 1/10, cost: 6.347801345169165, val_loss: 1.7301460728049278, train_acc: 0.53 val_acc: 0.54 \n",
            "2021-02-15 18:37:08.937114 Epoch 10/10, cost: 7.622651031442508, val_loss: 3.5924713760614395, train_acc: 0.50 val_acc: 0.50 \n",
            "(23/100)\n",
            "Lr: 0.0029942047567198746 Reg: 0.000684291236910784\n",
            "2021-02-15 18:37:10.041373 Epoch 1/10, cost: 0.39861405284921075, val_loss: 0.34226845344528556, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:37:16.594444 Epoch 10/10, cost: 0.21109678871502544, val_loss: 0.2660646182484925, train_acc: 0.93 val_acc: 0.92 \n",
            "(24/100)\n",
            "Lr: 0.035246086827184865 Reg: 0.00012027154699555562\n",
            "2021-02-15 18:37:17.629415 Epoch 1/10, cost: 0.5406881530953062, val_loss: 0.4800442401319742, train_acc: 0.78 val_acc: 0.78 \n",
            "2021-02-15 18:37:23.731204 Epoch 10/10, cost: 0.48595296216618483, val_loss: 0.4339294256642461, train_acc: 0.81 val_acc: 0.81 \n",
            "(25/100)\n",
            "Lr: 0.004225905163836507 Reg: 6.422034786929082e-05\n",
            "2021-02-15 18:37:24.642967 Epoch 1/10, cost: 0.3936249993409321, val_loss: 0.35966531932353973, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 18:37:31.014275 Epoch 10/10, cost: 0.2406517699076112, val_loss: 0.29110195906832814, train_acc: 0.91 val_acc: 0.90 \n",
            "(26/100)\n",
            "Lr: 356.087029447788 Reg: 2.7067146963502683e-06\n",
            "2021-02-15 18:37:31.940940 Epoch 1/10, cost: 5563.703662756142, val_loss: 1088.3807697296143, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:37:38.568749 Epoch 10/10, cost: 1637.764276783937, val_loss: 138.5832176208496, train_acc: 0.53 val_acc: 0.53 \n",
            "(27/100)\n",
            "Lr: 1.5983076971726486 Reg: 1.0669902056422172e-05\n",
            "2021-02-15 18:37:39.486354 Epoch 1/10, cost: 4.603016471786863, val_loss: 8.78302651643753, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:37:45.730468 Epoch 10/10, cost: 5.076456081335712, val_loss: 1.0017300751060247, train_acc: 0.50 val_acc: 0.50 \n",
            "(28/100)\n",
            "Lr: 0.002133285902241326 Reg: 0.0008886338840228975\n",
            "2021-02-15 18:37:46.679597 Epoch 1/10, cost: 0.3986619415746373, val_loss: 0.33453277265653014, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:37:53.032487 Epoch 10/10, cost: 0.1814866569723673, val_loss: 0.2951327378395945, train_acc: 0.93 val_acc: 0.92 \n",
            "(29/100)\n",
            "Lr: 28.773303507681568 Reg: 0.0003621355448652089\n",
            "2021-02-15 18:37:54.029066 Epoch 1/10, cost: 377.8556197243891, val_loss: 573.7082443237305, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:38:00.501354 Epoch 10/10, cost: 93.0862435216357, val_loss: 181.85344552993774, train_acc: 0.50 val_acc: 0.50 \n",
            "(30/100)\n",
            "Lr: 2550.096942179475 Reg: 3.957544558292851e-05\n",
            "2021-02-15 18:38:01.485743 Epoch 1/10, cost: 10094.42024873776, val_loss: 24641.73516845703, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:38:07.591375 Epoch 10/10, cost: 5900.45292741326, val_loss: 12240.919372558594, train_acc: 0.50 val_acc: 0.50 \n",
            "(31/100)\n",
            "Lr: 59557.2578811426 Reg: 3.2672433374127344e-05\n",
            "2021-02-15 18:38:08.558610 Epoch 1/10, cost: 101419.5094057424, val_loss: 67963.8212890625, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:38:15.109364 Epoch 10/10, cost: 95655.6861805521, val_loss: 16965.31558227539, train_acc: 0.50 val_acc: 0.50 \n",
            "(32/100)\n",
            "Lr: 0.3531526905966012 Reg: 0.00047502570593679504\n",
            "2021-02-15 18:38:16.036849 Epoch 1/10, cost: 0.9870639443397522, val_loss: 1.0533362571150064, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:38:22.242693 Epoch 10/10, cost: 0.9329324478556396, val_loss: 0.7075369581580162, train_acc: 0.50 val_acc: 0.50 \n",
            "(33/100)\n",
            "Lr: 0.02130564351447798 Reg: 1.6375577135103295e-06\n",
            "2021-02-15 18:38:23.175467 Epoch 1/10, cost: 0.5073970548666207, val_loss: 0.42644695844501257, train_acc: 0.81 val_acc: 0.81 \n",
            "2021-02-15 18:38:29.632347 Epoch 10/10, cost: 0.3951037019301372, val_loss: 0.3640210460871458, train_acc: 0.84 val_acc: 0.84 \n",
            "(34/100)\n",
            "Lr: 1.7187219502474414e-05 Reg: 4.4679694660524155e-06\n",
            "2021-02-15 18:38:30.570661 Epoch 1/10, cost: 0.572805768555137, val_loss: 0.49746816884726286, train_acc: 0.77 val_acc: 0.77 \n",
            "2021-02-15 18:38:36.938773 Epoch 10/10, cost: 0.3483108005895736, val_loss: 0.3509401148185134, train_acc: 0.85 val_acc: 0.85 \n",
            "(35/100)\n",
            "Lr: 7.696428694576951 Reg: 1.2566904190929357e-06\n",
            "2021-02-15 18:38:37.841573 Epoch 1/10, cost: 22.035998658010154, val_loss: 6.0100332498550415, train_acc: 0.52 val_acc: 0.52 \n",
            "2021-02-15 18:38:44.015401 Epoch 10/10, cost: 36.46579996491693, val_loss: 19.861118882894516, train_acc: 0.51 val_acc: 0.51 \n",
            "(36/100)\n",
            "Lr: 215.19686842713242 Reg: 2.718681757414664e-05\n",
            "2021-02-15 18:38:44.937357 Epoch 1/10, cost: 2332.0919841660816, val_loss: 1831.836410522461, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:38:51.384336 Epoch 10/10, cost: 789.0043527639596, val_loss: 422.2810411453247, train_acc: 0.50 val_acc: 0.50 \n",
            "(37/100)\n",
            "Lr: 0.33653161045915675 Reg: 2.6628549766101124e-06\n",
            "2021-02-15 18:38:52.387204 Epoch 1/10, cost: 1.0868072361703132, val_loss: 0.6979082487523556, train_acc: 0.56 val_acc: 0.56 \n",
            "2021-02-15 18:38:58.648877 Epoch 10/10, cost: 0.8405726502655418, val_loss: 1.3098876848816872, train_acc: 0.50 val_acc: 0.50 \n",
            "(38/100)\n",
            "Lr: 2.642541223302634 Reg: 0.00012759818934445795\n",
            "2021-02-15 18:38:59.561894 Epoch 1/10, cost: 10.977819564995492, val_loss: 5.006402134895325, train_acc: 0.68 val_acc: 0.68 \n",
            "2021-02-15 18:39:05.898918 Epoch 10/10, cost: 10.314502625708368, val_loss: 16.786288261413574, train_acc: 0.50 val_acc: 0.50 \n",
            "(39/100)\n",
            "Lr: 0.007524073397054518 Reg: 1.977819977322842e-06\n",
            "2021-02-15 18:39:06.817640 Epoch 1/10, cost: 0.4351830929517746, val_loss: 0.39811979979276657, train_acc: 0.83 val_acc: 0.83 \n",
            "2021-02-15 18:39:13.061223 Epoch 10/10, cost: 0.28446048284602016, val_loss: 0.2991331280209124, train_acc: 0.88 val_acc: 0.88 \n",
            "(40/100)\n",
            "Lr: 6150.767648049517 Reg: 1.713264348850033e-05\n",
            "2021-02-15 18:39:13.995325 Epoch 1/10, cost: 34854.064644856815, val_loss: 43469.47644042969, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:39:20.109510 Epoch 10/10, cost: 16505.619909978977, val_loss: 11544.238006591797, train_acc: 0.51 val_acc: 0.51 \n",
            "(41/100)\n",
            "Lr: 0.023749755130174927 Reg: 0.0004231073500444364\n",
            "2021-02-15 18:39:21.034395 Epoch 1/10, cost: 0.5319189484332018, val_loss: 0.43958818074315786, train_acc: 0.81 val_acc: 0.81 \n",
            "2021-02-15 18:39:27.205233 Epoch 10/10, cost: 0.4007817104363897, val_loss: 0.45376337226480246, train_acc: 0.80 val_acc: 0.80 \n",
            "(42/100)\n",
            "Lr: 5.818557736702662e-05 Reg: 0.0009861774347017984\n",
            "2021-02-15 18:39:28.118208 Epoch 1/10, cost: 0.511024091084292, val_loss: 0.43525843881070614, train_acc: 0.81 val_acc: 0.81 \n",
            "2021-02-15 18:39:34.256231 Epoch 10/10, cost: 0.2855418509548637, val_loss: 0.30581897404044867, train_acc: 0.89 val_acc: 0.88 \n",
            "(43/100)\n",
            "Lr: 0.05959548401161604 Reg: 0.0008776691569626694\n",
            "2021-02-15 18:39:35.217667 Epoch 1/10, cost: 0.5807194797096739, val_loss: 0.5168965859338641, train_acc: 0.75 val_acc: 0.76 \n",
            "2021-02-15 18:39:41.421972 Epoch 10/10, cost: 0.5810889806717064, val_loss: 0.6031154273077846, train_acc: 0.70 val_acc: 0.70 \n",
            "(44/100)\n",
            "Lr: 7945.431033628536 Reg: 1.5177041713197e-05\n",
            "2021-02-15 18:39:42.380953 Epoch 1/10, cost: 28715.89002702722, val_loss: 12617.494140625, train_acc: 0.48 val_acc: 0.48 \n",
            "2021-02-15 18:39:48.469873 Epoch 10/10, cost: 31088.971080609947, val_loss: 7869.1776123046875, train_acc: 0.50 val_acc: 0.50 \n",
            "(45/100)\n",
            "Lr: 0.013562408372372218 Reg: 2.904507742406707e-06\n",
            "2021-02-15 18:39:49.532375 Epoch 1/10, cost: 0.4554362733652637, val_loss: 0.406410894356668, train_acc: 0.83 val_acc: 0.83 \n",
            "2021-02-15 18:39:55.577414 Epoch 10/10, cost: 0.3465208339083726, val_loss: 0.3373264688998461, train_acc: 0.86 val_acc: 0.86 \n",
            "(46/100)\n",
            "Lr: 158.99319151785843 Reg: 3.9244593144974725e-05\n",
            "2021-02-15 18:39:56.527872 Epoch 1/10, cost: 1209.323924116648, val_loss: 2778.684295654297, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:40:02.653141 Epoch 10/10, cost: 632.7209147070623, val_loss: 751.5895366668701, train_acc: 0.50 val_acc: 0.50 \n",
            "(47/100)\n",
            "Lr: 0.0067721909929050065 Reg: 2.8916110691136487e-06\n",
            "2021-02-15 18:40:03.618577 Epoch 1/10, cost: 0.4074895753032842, val_loss: 0.3470671195536852, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 18:40:09.872405 Epoch 10/10, cost: 0.27090801179978496, val_loss: 0.2838996173813939, train_acc: 0.89 val_acc: 0.89 \n",
            "(48/100)\n",
            "Lr: 0.03323742417004179 Reg: 1.0530703664286393e-06\n",
            "2021-02-15 18:40:10.813392 Epoch 1/10, cost: 0.5513789555069747, val_loss: 0.5217965142801404, train_acc: 0.77 val_acc: 0.77 \n",
            "2021-02-15 18:40:17.057120 Epoch 10/10, cost: 0.4812498286271551, val_loss: 0.4489513114094734, train_acc: 0.81 val_acc: 0.81 \n",
            "(49/100)\n",
            "Lr: 0.0017124051463247004 Reg: 4.874897766171211e-06\n",
            "2021-02-15 18:40:18.042872 Epoch 1/10, cost: 0.38179658960764573, val_loss: 0.32223952282220125, train_acc: 0.87 val_acc: 0.87 \n",
            "2021-02-15 18:40:24.374269 Epoch 10/10, cost: 0.15999191959097886, val_loss: 0.27828665589913726, train_acc: 0.95 val_acc: 0.94 \n",
            "(50/100)\n",
            "Lr: 0.0007009062861834626 Reg: 1.4148477745137686e-05\n",
            "2021-02-15 18:40:25.359120 Epoch 1/10, cost: 0.39554353684756405, val_loss: 0.33062100876122713, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 18:40:31.969003 Epoch 10/10, cost: 0.17257366941612998, val_loss: 0.26616951590403914, train_acc: 0.94 val_acc: 0.94 \n",
            "(51/100)\n",
            "Lr: 0.09691047648734259 Reg: 2.5572619709937363e-05\n",
            "2021-02-15 18:40:33.006331 Epoch 1/10, cost: 0.6140508693494614, val_loss: 0.7841406036168337, train_acc: 0.70 val_acc: 0.70 \n",
            "2021-02-15 18:40:39.148158 Epoch 10/10, cost: 0.6371916046567784, val_loss: 1.1572868321090937, train_acc: 0.50 val_acc: 0.50 \n",
            "(52/100)\n",
            "Lr: 4.6208597641646406e-05 Reg: 0.0007265697356597056\n",
            "2021-02-15 18:40:40.073470 Epoch 1/10, cost: 0.5118365382692617, val_loss: 0.436691714450717, train_acc: 0.80 val_acc: 0.80 \n",
            "2021-02-15 18:40:46.224139 Epoch 10/10, cost: 0.29560539221308035, val_loss: 0.3083184496499598, train_acc: 0.88 val_acc: 0.88 \n",
            "(53/100)\n",
            "Lr: 0.0038019301046875215 Reg: 0.0007710771750969603\n",
            "2021-02-15 18:40:47.152527 Epoch 1/10, cost: 0.3896578934731757, val_loss: 0.3577174530364573, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:40:53.502110 Epoch 10/10, cost: 0.22034779020175813, val_loss: 0.27451825281605124, train_acc: 0.92 val_acc: 0.92 \n",
            "(54/100)\n",
            "Lr: 6003.615647745797 Reg: 7.291551309141577e-05\n",
            "2021-02-15 18:40:54.458177 Epoch 1/10, cost: 25907.584798538002, val_loss: 9026.86410522461, train_acc: 0.48 val_acc: 0.48 \n",
            "2021-02-15 18:41:00.946671 Epoch 10/10, cost: 11566.047109421652, val_loss: 4426.752098083496, train_acc: 0.51 val_acc: 0.51 \n",
            "(55/100)\n",
            "Lr: 21.849319584929813 Reg: 3.012968318444458e-06\n",
            "2021-02-15 18:41:01.854327 Epoch 1/10, cost: 89.61168231364269, val_loss: 8.86440959572792, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:41:08.260054 Epoch 10/10, cost: 76.8681830156381, val_loss: 37.07542008161545, train_acc: 0.50 val_acc: 0.50 \n",
            "(56/100)\n",
            "Lr: 0.0006844844302879502 Reg: 5.945023894309294e-05\n",
            "2021-02-15 18:41:09.207650 Epoch 1/10, cost: 0.3797457316878495, val_loss: 0.34220227459445596, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:41:15.441448 Epoch 10/10, cost: 0.16496568880263407, val_loss: 0.24301497591659427, train_acc: 0.95 val_acc: 0.94 \n",
            "(57/100)\n",
            "Lr: 9057.484265503772 Reg: 1.2615132262345983e-06\n",
            "2021-02-15 18:41:16.399718 Epoch 1/10, cost: 96085.45754345966, val_loss: 111080.02099609375, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:41:22.574146 Epoch 10/10, cost: 15099.262308886096, val_loss: 27183.247192382812, train_acc: 0.50 val_acc: 0.50 \n",
            "(58/100)\n",
            "Lr: 354.31128510536 Reg: 8.396836264668301e-06\n",
            "2021-02-15 18:41:23.605168 Epoch 1/10, cost: 6744.24125883268, val_loss: 10857.29116821289, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:41:29.870113 Epoch 10/10, cost: 1939.835737762937, val_loss: 2497.965171813965, train_acc: 0.50 val_acc: 0.50 \n",
            "(59/100)\n",
            "Lr: 5106.088632582217 Reg: 3.0892097676881676e-06\n",
            "2021-02-15 18:41:30.944579 Epoch 1/10, cost: 59433.30248493526, val_loss: 29180.626586914062, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:41:37.043121 Epoch 10/10, cost: 14570.741839949493, val_loss: 1596.3947792053223, train_acc: 0.65 val_acc: 0.65 \n",
            "(60/100)\n",
            "Lr: 22103.010338154843 Reg: 1.7643743897862797e-06\n",
            "2021-02-15 18:41:37.996243 Epoch 1/10, cost: 150558.03711348432, val_loss: 29463.897033691406, train_acc: 0.47 val_acc: 0.47 \n",
            "2021-02-15 18:41:44.698472 Epoch 10/10, cost: 135383.12560646396, val_loss: 22284.547790527344, train_acc: 0.50 val_acc: 0.50 \n",
            "(61/100)\n",
            "Lr: 0.8696516669430986 Reg: 1.284206120584183e-06\n",
            "2021-02-15 18:41:45.620652 Epoch 1/10, cost: 1.7098206029196454, val_loss: 4.837138965725899, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:41:51.616817 Epoch 10/10, cost: 1.9660329120174336, val_loss: 0.7074960116297007, train_acc: 0.50 val_acc: 0.50 \n",
            "(62/100)\n",
            "Lr: 0.0009000658625533417 Reg: 4.849250143850213e-05\n",
            "2021-02-15 18:41:52.654055 Epoch 1/10, cost: 0.38462343024220436, val_loss: 0.343801723793149, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 18:41:59.013919 Epoch 10/10, cost: 0.14887984948837832, val_loss: 0.25466530164703727, train_acc: 0.95 val_acc: 0.94 \n",
            "(63/100)\n",
            "Lr: 0.005303379351003884 Reg: 2.8703453117203643e-06\n",
            "2021-02-15 18:41:59.937916 Epoch 1/10, cost: 0.43719418242478825, val_loss: 0.3652337668463588, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 18:42:06.161367 Epoch 10/10, cost: 0.25346667362246544, val_loss: 0.2910741944797337, train_acc: 0.90 val_acc: 0.90 \n",
            "(64/100)\n",
            "Lr: 0.02990278631497018 Reg: 1.786244240099328e-05\n",
            "2021-02-15 18:42:07.090243 Epoch 1/10, cost: 0.5361957903595487, val_loss: 0.5080303335562348, train_acc: 0.78 val_acc: 0.78 \n",
            "2021-02-15 18:42:13.135236 Epoch 10/10, cost: 0.46981408148054865, val_loss: 0.4733009273186326, train_acc: 0.77 val_acc: 0.77 \n",
            "(65/100)\n",
            "Lr: 166.10219303786616 Reg: 0.00020980750336887415\n",
            "2021-02-15 18:42:14.179100 Epoch 1/10, cost: 1238.1120084846855, val_loss: 883.9726257324219, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:42:20.125874 Epoch 10/10, cost: 464.87249958439236, val_loss: 101.43061566352844, train_acc: 0.50 val_acc: 0.50 \n",
            "(66/100)\n",
            "Lr: 0.31874856377764976 Reg: 4.380358470581635e-05\n",
            "2021-02-15 18:42:21.056819 Epoch 1/10, cost: 1.0113591965596387, val_loss: 0.699373260140419, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:42:27.425551 Epoch 10/10, cost: 1.0239326828604292, val_loss: 0.8254208415746689, train_acc: 0.50 val_acc: 0.50 \n",
            "(67/100)\n",
            "Lr: 0.0010368115448668245 Reg: 1.359819468428755e-05\n",
            "2021-02-15 18:42:28.337946 Epoch 1/10, cost: 0.40064480454678747, val_loss: 0.336375473998487, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 18:42:34.407591 Epoch 10/10, cost: 0.1622864130860681, val_loss: 0.28296349104493856, train_acc: 0.94 val_acc: 0.93 \n",
            "(68/100)\n",
            "Lr: 0.0004528485296451701 Reg: 1.1854562126254196e-06\n",
            "2021-02-15 18:42:35.323911 Epoch 1/10, cost: 0.39781763181564916, val_loss: 0.3469537138007581, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 18:42:41.342182 Epoch 10/10, cost: 0.1775907262400457, val_loss: 0.2532812152057886, train_acc: 0.95 val_acc: 0.94 \n",
            "(69/100)\n",
            "Lr: 240.6530720419826 Reg: 2.9323520413840063e-06\n",
            "2021-02-15 18:42:42.352304 Epoch 1/10, cost: 1696.001171039548, val_loss: 2183.9700965881348, train_acc: 0.51 val_acc: 0.51 \n",
            "2021-02-15 18:42:48.783775 Epoch 10/10, cost: 964.6612416164131, val_loss: 250.598162651062, train_acc: 0.50 val_acc: 0.50 \n",
            "(70/100)\n",
            "Lr: 64508.21676165477 Reg: 3.17259944853326e-05\n",
            "2021-02-15 18:42:49.715090 Epoch 1/10, cost: 80331.60050311172, val_loss: 29857.24298095703, train_acc: 0.53 val_acc: 0.53 \n",
            "2021-02-15 18:42:56.076456 Epoch 10/10, cost: 102073.16063520104, val_loss: 21075.153381347656, train_acc: 0.50 val_acc: 0.50 \n",
            "(71/100)\n",
            "Lr: 0.0037860373824704324 Reg: 5.437865931509688e-05\n",
            "2021-02-15 18:42:57.013257 Epoch 1/10, cost: 0.41093744489417716, val_loss: 0.36891194619238377, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:43:03.145291 Epoch 10/10, cost: 0.21721343446973781, val_loss: 0.28590220445767045, train_acc: 0.92 val_acc: 0.91 \n",
            "(72/100)\n",
            "Lr: 6.108632533456447e-05 Reg: 2.8905965701803763e-05\n",
            "2021-02-15 18:43:04.092049 Epoch 1/10, cost: 0.49765425199156355, val_loss: 0.42675355076789856, train_acc: 0.80 val_acc: 0.80 \n",
            "2021-02-15 18:43:10.375927 Epoch 10/10, cost: 0.28347037628198124, val_loss: 0.2930039674974978, train_acc: 0.88 val_acc: 0.88 \n",
            "(73/100)\n",
            "Lr: 28.586368293513974 Reg: 0.00029211397341571906\n",
            "2021-02-15 18:43:11.348741 Epoch 1/10, cost: 301.052610020349, val_loss: 1222.0365829467773, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:43:17.387628 Epoch 10/10, cost: 113.2367570840629, val_loss: 94.91591286659241, train_acc: 0.50 val_acc: 0.50 \n",
            "(74/100)\n",
            "Lr: 0.0004183987148598261 Reg: 3.964144562799131e-06\n",
            "2021-02-15 18:43:18.360020 Epoch 1/10, cost: 0.3967987290423387, val_loss: 0.3429068699479103, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:43:24.555420 Epoch 10/10, cost: 0.18161815034735734, val_loss: 0.2526685893535614, train_acc: 0.94 val_acc: 0.93 \n",
            "(75/100)\n",
            "Lr: 0.9963396533074447 Reg: 1.9546566746256952e-05\n",
            "2021-02-15 18:43:25.599088 Epoch 1/10, cost: 3.834682738705046, val_loss: 3.9362954422831535, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:43:31.837675 Epoch 10/10, cost: 1.8924052331857621, val_loss: 6.4481199979782104, train_acc: 0.50 val_acc: 0.50 \n",
            "(76/100)\n",
            "Lr: 327.4448620378373 Reg: 0.00020428269319539713\n",
            "2021-02-15 18:43:32.751474 Epoch 1/10, cost: 1476.1356922657626, val_loss: 1474.8935089111328, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:43:39.287752 Epoch 10/10, cost: 914.0652754971176, val_loss: 1075.091604232788, train_acc: 0.50 val_acc: 0.50 \n",
            "(77/100)\n",
            "Lr: 0.019050582104017225 Reg: 0.0006703181273841742\n",
            "2021-02-15 18:43:40.300718 Epoch 1/10, cost: 0.5024616910014182, val_loss: 0.4154259115457535, train_acc: 0.81 val_acc: 0.81 \n",
            "2021-02-15 18:43:46.547345 Epoch 10/10, cost: 0.3623736545348623, val_loss: 0.4183422587811947, train_acc: 0.83 val_acc: 0.83 \n",
            "(78/100)\n",
            "Lr: 0.029728008339606798 Reg: 4.067423617283365e-06\n",
            "2021-02-15 18:43:47.465633 Epoch 1/10, cost: 0.5110780125970293, val_loss: 0.4539791764691472, train_acc: 0.80 val_acc: 0.80 \n",
            "2021-02-15 18:43:53.427301 Epoch 10/10, cost: 0.4864257431713639, val_loss: 0.4278469253331423, train_acc: 0.80 val_acc: 0.81 \n",
            "(79/100)\n",
            "Lr: 1.1447736232930436e-05 Reg: 0.0001365572506229094\n",
            "2021-02-15 18:43:54.434573 Epoch 1/10, cost: 0.5953790524582954, val_loss: 0.5233202734962106, train_acc: 0.76 val_acc: 0.76 \n",
            "2021-02-15 18:44:00.816170 Epoch 10/10, cost: 0.3683874048055357, val_loss: 0.36252397391945124, train_acc: 0.84 val_acc: 0.84 \n",
            "(80/100)\n",
            "Lr: 413.19134376822836 Reg: 0.00012767252064744362\n",
            "2021-02-15 18:44:01.741685 Epoch 1/10, cost: 2589.593570654939, val_loss: 2684.3127365112305, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:44:08.038155 Epoch 10/10, cost: 1091.8087078811257, val_loss: 515.8588008880615, train_acc: 0.50 val_acc: 0.50 \n",
            "(81/100)\n",
            "Lr: 2.3675131300275103 Reg: 4.102283197848443e-06\n",
            "2021-02-15 18:44:08.952489 Epoch 1/10, cost: 8.808704309402758, val_loss: 1.9270296357572079, train_acc: 0.54 val_acc: 0.55 \n",
            "2021-02-15 18:44:15.758772 Epoch 10/10, cost: 6.305638837206895, val_loss: 6.821879178285599, train_acc: 0.50 val_acc: 0.50 \n",
            "(82/100)\n",
            "Lr: 0.0015994242045962834 Reg: 1.2297417988483919e-06\n",
            "2021-02-15 18:44:16.847483 Epoch 1/10, cost: 0.3895470025433097, val_loss: 0.3408632790669799, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 18:44:23.108066 Epoch 10/10, cost: 0.16239669181074307, val_loss: 0.26388284005224705, train_acc: 0.95 val_acc: 0.94 \n",
            "(83/100)\n",
            "Lr: 3890.7333443933053 Reg: 0.00011391069237000695\n",
            "2021-02-15 18:44:24.054469 Epoch 1/10, cost: 11815.92710292795, val_loss: 13230.026184082031, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:44:30.368989 Epoch 10/10, cost: 6920.26984808855, val_loss: 9945.566131591797, train_acc: 0.50 val_acc: 0.50 \n",
            "(84/100)\n",
            "Lr: 4.798400794135602e-05 Reg: 1.5623885230309386e-06\n",
            "2021-02-15 18:44:31.333705 Epoch 1/10, cost: 0.5217922922152622, val_loss: 0.44822817388921976, train_acc: 0.79 val_acc: 0.79 \n",
            "2021-02-15 18:44:38.161619 Epoch 10/10, cost: 0.2988749370453464, val_loss: 0.3132933001033962, train_acc: 0.88 val_acc: 0.88 \n",
            "(85/100)\n",
            "Lr: 0.798846803404211 Reg: 0.0004623523002028989\n",
            "2021-02-15 18:44:39.107444 Epoch 1/10, cost: 2.225282586683893, val_loss: 1.45169498026371, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:44:45.537568 Epoch 10/10, cost: 1.7059174225588514, val_loss: 0.6914509553462267, train_acc: 0.62 val_acc: 0.63 \n",
            "(86/100)\n",
            "Lr: 0.0832751520157762 Reg: 1.4516180086361407e-06\n",
            "2021-02-15 18:44:46.506305 Epoch 1/10, cost: 0.6144247227793287, val_loss: 0.5360867977142334, train_acc: 0.72 val_acc: 0.72 \n",
            "2021-02-15 18:44:53.236547 Epoch 10/10, cost: 0.6036426979265396, val_loss: 0.7167820539325476, train_acc: 0.55 val_acc: 0.55 \n",
            "(87/100)\n",
            "Lr: 0.000989687823207755 Reg: 0.0003189496336507901\n",
            "2021-02-15 18:44:54.188597 Epoch 1/10, cost: 0.3796410512202864, val_loss: 0.32290208525955677, train_acc: 0.87 val_acc: 0.87 \n",
            "2021-02-15 18:45:00.535333 Epoch 10/10, cost: 0.1599640386641785, val_loss: 0.264669754775241, train_acc: 0.95 val_acc: 0.94 \n",
            "(88/100)\n",
            "Lr: 0.07902167671068412 Reg: 3.315864372866504e-06\n",
            "2021-02-15 18:45:01.581114 Epoch 1/10, cost: 0.6268156372058163, val_loss: 0.6322463825345039, train_acc: 0.63 val_acc: 0.63 \n",
            "2021-02-15 18:45:08.289034 Epoch 10/10, cost: 0.6085414848509868, val_loss: 0.6884711366146803, train_acc: 0.54 val_acc: 0.54 \n",
            "(89/100)\n",
            "Lr: 0.8064264284581241 Reg: 0.00013445507919754892\n",
            "2021-02-15 18:45:09.212155 Epoch 1/10, cost: 2.555733615046094, val_loss: 2.3673858642578125, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:45:15.253688 Epoch 10/10, cost: 2.4135008473305186, val_loss: 1.6569358818233013, train_acc: 0.50 val_acc: 0.50 \n",
            "(90/100)\n",
            "Lr: 0.00670122480304456 Reg: 1.299684343568795e-06\n",
            "2021-02-15 18:45:16.292050 Epoch 1/10, cost: 0.42108502205769727, val_loss: 0.3580651469528675, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 18:45:22.688431 Epoch 10/10, cost: 0.27103280261823326, val_loss: 0.31337353121489286, train_acc: 0.89 val_acc: 0.89 \n",
            "(91/100)\n",
            "Lr: 42.21926261773638 Reg: 3.094683824876583e-05\n",
            "2021-02-15 18:45:23.632287 Epoch 1/10, cost: 348.6418684462833, val_loss: 781.0871295928955, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:45:30.353983 Epoch 10/10, cost: 200.53338118723244, val_loss: 144.55613327026367, train_acc: 0.50 val_acc: 0.50 \n",
            "(92/100)\n",
            "Lr: 0.0042991459365983265 Reg: 1.3939767025623806e-06\n",
            "2021-02-15 18:45:31.328927 Epoch 1/10, cost: 0.4198716819096523, val_loss: 0.3506573876366019, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 18:45:37.702676 Epoch 10/10, cost: 0.2485320290942101, val_loss: 0.29563462594524026, train_acc: 0.90 val_acc: 0.89 \n",
            "(93/100)\n",
            "Lr: 13.236153717482022 Reg: 0.000221476614768197\n",
            "2021-02-15 18:45:38.666492 Epoch 1/10, cost: 74.40762769758322, val_loss: 94.86167097091675, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:45:45.318873 Epoch 10/10, cost: 49.860162013655255, val_loss: 32.63421314954758, train_acc: 0.50 val_acc: 0.50 \n",
            "(94/100)\n",
            "Lr: 9.942534848100474 Reg: 1.6044993941198292e-05\n",
            "2021-02-15 18:45:46.258827 Epoch 1/10, cost: 52.61896809347116, val_loss: 19.725616455078125, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:45:52.563171 Epoch 10/10, cost: 44.06187558098204, val_loss: 33.214783012866974, train_acc: 0.50 val_acc: 0.50 \n",
            "(95/100)\n",
            "Lr: 1.83844421167067 Reg: 2.4964733942461633e-05\n",
            "2021-02-15 18:45:53.571448 Epoch 1/10, cost: 5.601629706704692, val_loss: 6.580807104706764, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:46:00.053681 Epoch 10/10, cost: 6.091601752931146, val_loss: 8.821656584739685, train_acc: 0.50 val_acc: 0.50 \n",
            "(96/100)\n",
            "Lr: 6.703180094038322 Reg: 7.327851637738451e-05\n",
            "2021-02-15 18:46:01.129197 Epoch 1/10, cost: 42.60528018937749, val_loss: 136.07476162910461, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:46:07.300921 Epoch 10/10, cost: 24.38817621833959, val_loss: 61.79248559474945, train_acc: 0.50 val_acc: 0.50 \n",
            "(97/100)\n",
            "Lr: 0.005372830122877895 Reg: 7.696701231678688e-05\n",
            "2021-02-15 18:46:08.314460 Epoch 1/10, cost: 0.4010406122750537, val_loss: 0.383977391757071, train_acc: 0.83 val_acc: 0.83 \n",
            "2021-02-15 18:46:14.715873 Epoch 10/10, cost: 0.26683022423534636, val_loss: 0.276999665889889, train_acc: 0.91 val_acc: 0.90 \n",
            "(98/100)\n",
            "Lr: 110.56872246890822 Reg: 0.00029983192658318775\n",
            "2021-02-15 18:46:15.625033 Epoch 1/10, cost: 1137.5720758673492, val_loss: 1326.4270095825195, train_acc: 0.50 val_acc: 0.50 \n",
            "2021-02-15 18:46:21.939734 Epoch 10/10, cost: 317.1197280488956, val_loss: 184.31779146194458, train_acc: 0.50 val_acc: 0.50 \n",
            "(99/100)\n",
            "Lr: 0.00012570962049739142 Reg: 7.031252383838542e-05\n",
            "2021-02-15 18:46:23.009831 Epoch 1/10, cost: 0.46457528669363374, val_loss: 0.379286028444767, train_acc: 0.84 val_acc: 0.83 \n",
            "2021-02-15 18:46:29.302277 Epoch 10/10, cost: 0.24521296846259172, val_loss: 0.2848010933957994, train_acc: 0.90 val_acc: 0.90 \n",
            "(100/100)\n",
            "Lr: 3.1151666927389115e-05 Reg: 1.5297000792800082e-06\n",
            "2021-02-15 18:46:30.319476 Epoch 1/10, cost: 0.5438430624403012, val_loss: 0.47990537621080875, train_acc: 0.78 val_acc: 0.78 \n",
            "2021-02-15 18:46:36.488364 Epoch 10/10, cost: 0.3217703286249926, val_loss: 0.330352483317256, train_acc: 0.86 val_acc: 0.86 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIITbMh4J0CL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327adb57-ad8b-44a9-dfd1-3ac038cdf4fb"
      },
      "source": [
        "lr = math.log10(0.0011863)\r\n",
        "run_tuning(50, lr_s=(lr,lr), reg_s=(math.log10(0.000010552),math.log10(0.000015013)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0/50)\n",
            "Lr: 0.0011863 Reg: 1.3534334571744408e-05\n",
            "2021-02-15 19:00:46.770801 Epoch 1/10, cost: 0.3799357696133814, val_loss: 0.3397082663141191, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:00:53.395962 Epoch 10/10, cost: 0.1508263599151259, val_loss: 0.27446932322345674, train_acc: 0.96 val_acc: 0.94 \n",
            "(1/50)\n",
            "Lr: 0.0011863 Reg: 1.3835537323377932e-05\n",
            "2021-02-15 19:00:54.382887 Epoch 1/10, cost: 0.3866941856730516, val_loss: 0.3524814238771796, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:01:00.875826 Epoch 10/10, cost: 0.13898656166093365, val_loss: 0.2564171764533967, train_acc: 0.96 val_acc: 0.95 \n",
            "(2/50)\n",
            "Lr: 0.0011863 Reg: 1.4962744500000637e-05\n",
            "2021-02-15 19:01:01.963743 Epoch 1/10, cost: 0.3884017639289236, val_loss: 0.3384848930872977, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:01:08.125161 Epoch 10/10, cost: 0.15749362175157117, val_loss: 0.2576418952085078, train_acc: 0.96 val_acc: 0.94 \n",
            "(3/50)\n",
            "Lr: 0.0011863 Reg: 1.1027678284811846e-05\n",
            "2021-02-15 19:01:09.050656 Epoch 1/10, cost: 0.3991270981207015, val_loss: 0.35381484776735306, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:01:15.820418 Epoch 10/10, cost: 0.14279311582161364, val_loss: 0.24724885122850537, train_acc: 0.96 val_acc: 0.95 \n",
            "(4/50)\n",
            "Lr: 0.0011863 Reg: 1.2694752521263352e-05\n",
            "2021-02-15 19:01:16.740526 Epoch 1/10, cost: 0.38646992547496867, val_loss: 0.37113762740045786, train_acc: 0.85 val_acc: 0.84 \n",
            "2021-02-15 19:01:23.421519 Epoch 10/10, cost: 0.1341996275980002, val_loss: 0.2385725227650255, train_acc: 0.96 val_acc: 0.95 \n",
            "(5/50)\n",
            "Lr: 0.0011863 Reg: 1.48032258797203e-05\n",
            "2021-02-15 19:01:24.437264 Epoch 1/10, cost: 0.38413034740147317, val_loss: 0.35200759721919894, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 19:01:30.920039 Epoch 10/10, cost: 0.14857977688027796, val_loss: 0.26369864074513316, train_acc: 0.96 val_acc: 0.95 \n",
            "(6/50)\n",
            "Lr: 0.0011863 Reg: 1.316770695626182e-05\n",
            "2021-02-15 19:01:31.840061 Epoch 1/10, cost: 0.3831570894475196, val_loss: 0.3510109926573932, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:01:38.014060 Epoch 10/10, cost: 0.1360618940726587, val_loss: 0.30221376940608025, train_acc: 0.95 val_acc: 0.94 \n",
            "(7/50)\n",
            "Lr: 0.0011863 Reg: 1.205525528634305e-05\n",
            "2021-02-15 19:01:39.064546 Epoch 1/10, cost: 0.3907182237524895, val_loss: 0.3344745356589556, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:01:45.243892 Epoch 10/10, cost: 0.16286815313776587, val_loss: 0.2562598509248346, train_acc: 0.96 val_acc: 0.95 \n",
            "(8/50)\n",
            "Lr: 0.0011863 Reg: 1.0712900458722994e-05\n",
            "2021-02-15 19:01:46.215411 Epoch 1/10, cost: 0.386931901334957, val_loss: 0.32018799567595124, train_acc: 0.87 val_acc: 0.87 \n",
            "2021-02-15 19:01:52.718836 Epoch 10/10, cost: 0.1444240615341314, val_loss: 0.2645698329433799, train_acc: 0.96 val_acc: 0.95 \n",
            "(9/50)\n",
            "Lr: 0.0011863 Reg: 1.4333306208895071e-05\n",
            "2021-02-15 19:01:53.705874 Epoch 1/10, cost: 0.3844941092334735, val_loss: 0.3457377231679857, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:00.336049 Epoch 10/10, cost: 0.15043606077599678, val_loss: 0.25782311521470547, train_acc: 0.96 val_acc: 0.95 \n",
            "(10/50)\n",
            "Lr: 0.0011863 Reg: 1.3166426468552266e-05\n",
            "2021-02-15 19:02:01.252426 Epoch 1/10, cost: 0.3760061265936323, val_loss: 0.32803245866671205, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:02:07.756335 Epoch 10/10, cost: 0.16016023202686552, val_loss: 0.286069821100682, train_acc: 0.95 val_acc: 0.94 \n",
            "(11/50)\n",
            "Lr: 0.0011863 Reg: 1.0815597359273502e-05\n",
            "2021-02-15 19:02:08.679368 Epoch 1/10, cost: 0.387874628992597, val_loss: 0.3494078773073852, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:15.172447 Epoch 10/10, cost: 0.16435776655651202, val_loss: 0.2639533735346049, train_acc: 0.95 val_acc: 0.94 \n",
            "(12/50)\n",
            "Lr: 0.0011863 Reg: 1.4350036666561656e-05\n",
            "2021-02-15 19:02:16.172604 Epoch 1/10, cost: 0.39363024787158724, val_loss: 0.3430154346860945, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:22.214982 Epoch 10/10, cost: 0.1580677991080436, val_loss: 0.2730693609919399, train_acc: 0.95 val_acc: 0.94 \n",
            "(13/50)\n",
            "Lr: 0.0011863 Reg: 1.0966213219696312e-05\n",
            "2021-02-15 19:02:23.139416 Epoch 1/10, cost: 0.37580924723178716, val_loss: 0.32586055202409625, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:29.636289 Epoch 10/10, cost: 0.14366534181461213, val_loss: 0.2880159053020179, train_acc: 0.95 val_acc: 0.94 \n",
            "(14/50)\n",
            "Lr: 0.0011863 Reg: 1.4295830400840057e-05\n",
            "2021-02-15 19:02:30.546453 Epoch 1/10, cost: 0.3866270039301769, val_loss: 0.3164540412835777, train_acc: 0.87 val_acc: 0.87 \n",
            "2021-02-15 19:02:36.602544 Epoch 10/10, cost: 0.13882721485985314, val_loss: 0.27249325439333916, train_acc: 0.96 val_acc: 0.94 \n",
            "(15/50)\n",
            "Lr: 0.0011863 Reg: 1.2030747138269984e-05\n",
            "2021-02-15 19:02:37.537700 Epoch 1/10, cost: 0.38212359948143076, val_loss: 0.326969301328063, train_acc: 0.87 val_acc: 0.87 \n",
            "2021-02-15 19:02:43.665269 Epoch 10/10, cost: 0.14088529445658063, val_loss: 0.3022528914734721, train_acc: 0.95 val_acc: 0.94 \n",
            "(16/50)\n",
            "Lr: 0.0011863 Reg: 1.1505509441511951e-05\n",
            "2021-02-15 19:02:44.582595 Epoch 1/10, cost: 0.3919610443768228, val_loss: 0.3500620052218437, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:51.188538 Epoch 10/10, cost: 0.1441584315839087, val_loss: 0.2705279099754989, train_acc: 0.95 val_acc: 0.94 \n",
            "(17/50)\n",
            "Lr: 0.0011863 Reg: 1.3420619898903526e-05\n",
            "2021-02-15 19:02:52.168795 Epoch 1/10, cost: 0.3856851088393266, val_loss: 0.3395918672904372, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:02:58.583405 Epoch 10/10, cost: 0.1380789172924628, val_loss: 0.2703993171453476, train_acc: 0.95 val_acc: 0.94 \n",
            "(18/50)\n",
            "Lr: 0.0011863 Reg: 1.2906669346046137e-05\n",
            "2021-02-15 19:02:59.495217 Epoch 1/10, cost: 0.3899263238451283, val_loss: 0.3579962132498622, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:03:05.450125 Epoch 10/10, cost: 0.16071159444796812, val_loss: 0.2525356858968735, train_acc: 0.94 val_acc: 0.94 \n",
            "(19/50)\n",
            "Lr: 0.0011863 Reg: 1.333216587415035e-05\n",
            "2021-02-15 19:03:06.454122 Epoch 1/10, cost: 0.3807946492911904, val_loss: 0.33897044882178307, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:03:12.897913 Epoch 10/10, cost: 0.1401611996494281, val_loss: 0.2813911270350218, train_acc: 0.96 val_acc: 0.95 \n",
            "(20/50)\n",
            "Lr: 0.0011863 Reg: 1.3524287477072615e-05\n",
            "2021-02-15 19:03:13.998418 Epoch 1/10, cost: 0.39262236967967573, val_loss: 0.3287754086777568, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:03:20.244378 Epoch 10/10, cost: 0.16052797083167514, val_loss: 0.28592973737977445, train_acc: 0.94 val_acc: 0.94 \n",
            "(21/50)\n",
            "Lr: 0.0011863 Reg: 1.2886609227150126e-05\n",
            "2021-02-15 19:03:21.154603 Epoch 1/10, cost: 0.3886114190907995, val_loss: 0.33347034780308604, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:03:27.208403 Epoch 10/10, cost: 0.1559745171077692, val_loss: 0.269055915530771, train_acc: 0.95 val_acc: 0.94 \n",
            "(22/50)\n",
            "Lr: 0.0011863 Reg: 1.1980689683818208e-05\n",
            "2021-02-15 19:03:28.147451 Epoch 1/10, cost: 0.38512259940053245, val_loss: 0.33641528990119696, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:03:34.671660 Epoch 10/10, cost: 0.14385718335011963, val_loss: 0.2498970243614167, train_acc: 0.96 val_acc: 0.95 \n",
            "(23/50)\n",
            "Lr: 0.0011863 Reg: 1.4749099699321622e-05\n",
            "2021-02-15 19:03:35.634131 Epoch 1/10, cost: 0.38831313808632506, val_loss: 0.3389622559770942, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:03:42.036138 Epoch 10/10, cost: 0.1464746542227496, val_loss: 0.30109284864738584, train_acc: 0.95 val_acc: 0.94 \n",
            "(24/50)\n",
            "Lr: 0.0011863 Reg: 1.3102827388496953e-05\n",
            "2021-02-15 19:03:43.013521 Epoch 1/10, cost: 0.3743260163979925, val_loss: 0.3332334356382489, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:03:49.328960 Epoch 10/10, cost: 0.14520267980873205, val_loss: 0.27141795377247036, train_acc: 0.96 val_acc: 0.95 \n",
            "(25/50)\n",
            "Lr: 0.0011863 Reg: 1.4541007210103356e-05\n",
            "2021-02-15 19:03:50.240737 Epoch 1/10, cost: 0.37963674905573486, val_loss: 0.34124917443841696, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:03:56.536488 Epoch 10/10, cost: 0.1435488216151857, val_loss: 0.26011695456691086, train_acc: 0.96 val_acc: 0.95 \n",
            "(26/50)\n",
            "Lr: 0.0011863 Reg: 1.064190256506251e-05\n",
            "2021-02-15 19:03:57.514032 Epoch 1/10, cost: 0.40271579070835356, val_loss: 0.33732506493106484, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:04:03.600463 Epoch 10/10, cost: 0.14601752379090543, val_loss: 0.27889323933050036, train_acc: 0.94 val_acc: 0.93 \n",
            "(27/50)\n",
            "Lr: 0.0011863 Reg: 1.4194293047076348e-05\n",
            "2021-02-15 19:04:04.562644 Epoch 1/10, cost: 0.38486180895832695, val_loss: 0.37725962651893497, train_acc: 0.84 val_acc: 0.84 \n",
            "2021-02-15 19:04:10.594277 Epoch 10/10, cost: 0.14788928260184397, val_loss: 0.282574194483459, train_acc: 0.96 val_acc: 0.94 \n",
            "(28/50)\n",
            "Lr: 0.0011863 Reg: 1.2968926170129244e-05\n",
            "2021-02-15 19:04:11.510767 Epoch 1/10, cost: 0.3998190175955463, val_loss: 0.33512086188420653, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:04:17.578155 Epoch 10/10, cost: 0.13868014379196866, val_loss: 0.2896738797426224, train_acc: 0.95 val_acc: 0.94 \n",
            "(29/50)\n",
            "Lr: 0.0011863 Reg: 1.3386357087040425e-05\n",
            "2021-02-15 19:04:18.596430 Epoch 1/10, cost: 0.39486518805953347, val_loss: 0.35368197318166494, train_acc: 0.85 val_acc: 0.84 \n",
            "2021-02-15 19:04:25.348130 Epoch 10/10, cost: 0.13394777565174232, val_loss: 0.26649497309699655, train_acc: 0.96 val_acc: 0.95 \n",
            "(30/50)\n",
            "Lr: 0.0011863 Reg: 1.3078168975644982e-05\n",
            "2021-02-15 19:04:26.371638 Epoch 1/10, cost: 0.38300136585903777, val_loss: 0.35179727245122194, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:04:32.840359 Epoch 10/10, cost: 0.14422069091326112, val_loss: 0.2882053810171783, train_acc: 0.94 val_acc: 0.93 \n",
            "(31/50)\n",
            "Lr: 0.0011863 Reg: 1.152718875301085e-05\n",
            "2021-02-15 19:04:33.755619 Epoch 1/10, cost: 0.37403554046989246, val_loss: 0.3276717117987573, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:04:39.946996 Epoch 10/10, cost: 0.1500362975961843, val_loss: 0.24935756204649806, train_acc: 0.96 val_acc: 0.95 \n",
            "(32/50)\n",
            "Lr: 0.0011863 Reg: 1.4153085578391134e-05\n",
            "2021-02-15 19:04:40.870788 Epoch 1/10, cost: 0.37574188752918486, val_loss: 0.4074540054425597, train_acc: 0.83 val_acc: 0.83 \n",
            "2021-02-15 19:04:47.023227 Epoch 10/10, cost: 0.1325350432733821, val_loss: 0.2578874262981117, train_acc: 0.97 val_acc: 0.96 \n",
            "(33/50)\n",
            "Lr: 0.0011863 Reg: 1.3017229592219676e-05\n",
            "2021-02-15 19:04:47.969514 Epoch 1/10, cost: 0.38460539490174334, val_loss: 0.3418467384763062, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:04:54.505202 Epoch 10/10, cost: 0.1531185322933516, val_loss: 0.26589707052335143, train_acc: 0.95 val_acc: 0.94 \n",
            "(34/50)\n",
            "Lr: 0.0011863 Reg: 1.1245485459125361e-05\n",
            "2021-02-15 19:04:55.487733 Epoch 1/10, cost: 0.3876484583137901, val_loss: 0.32059401692822576, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:01.925011 Epoch 10/10, cost: 0.14190648797496108, val_loss: 0.26379110664129257, train_acc: 0.96 val_acc: 0.94 \n",
            "(35/50)\n",
            "Lr: 0.0011863 Reg: 1.2973289085940545e-05\n",
            "2021-02-15 19:05:02.880182 Epoch 1/10, cost: 0.39175328764186546, val_loss: 0.33921057684347034, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:09.491729 Epoch 10/10, cost: 0.15645054310180578, val_loss: 0.25114004453644156, train_acc: 0.95 val_acc: 0.95 \n",
            "(36/50)\n",
            "Lr: 0.0011863 Reg: 1.1725747475489863e-05\n",
            "2021-02-15 19:05:10.582448 Epoch 1/10, cost: 0.3900669368968648, val_loss: 0.3436524006538093, train_acc: 0.85 val_acc: 0.85 \n",
            "2021-02-15 19:05:16.928619 Epoch 10/10, cost: 0.14459965703119138, val_loss: 0.25768863083794713, train_acc: 0.96 val_acc: 0.95 \n",
            "(37/50)\n",
            "Lr: 0.0011863 Reg: 1.1406724910957437e-05\n",
            "2021-02-15 19:05:17.899673 Epoch 1/10, cost: 0.39375331561276866, val_loss: 0.32751014456152916, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:05:23.947871 Epoch 10/10, cost: 0.14671158894991418, val_loss: 0.26542256586253643, train_acc: 0.95 val_acc: 0.95 \n",
            "(38/50)\n",
            "Lr: 0.0011863 Reg: 1.4259303285612212e-05\n",
            "2021-02-15 19:05:24.866262 Epoch 1/10, cost: 0.3920998889359699, val_loss: 0.33202061522752047, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:30.958266 Epoch 10/10, cost: 0.14124806329702874, val_loss: 0.2611799272708595, train_acc: 0.95 val_acc: 0.95 \n",
            "(39/50)\n",
            "Lr: 0.0011863 Reg: 1.1995903693259447e-05\n",
            "2021-02-15 19:05:31.885588 Epoch 1/10, cost: 0.3870226536776609, val_loss: 0.329479546751827, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:37.884336 Epoch 10/10, cost: 0.1473590258247913, val_loss: 0.2567177538294345, train_acc: 0.96 val_acc: 0.95 \n",
            "(40/50)\n",
            "Lr: 0.0011863 Reg: 1.4460256082715377e-05\n",
            "2021-02-15 19:05:38.824759 Epoch 1/10, cost: 0.3862857706607527, val_loss: 0.3366797724738717, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:05:45.039450 Epoch 10/10, cost: 0.13847612765184633, val_loss: 0.25693093915469944, train_acc: 0.96 val_acc: 0.95 \n",
            "(41/50)\n",
            "Lr: 0.0011863 Reg: 1.2480473684608943e-05\n",
            "2021-02-15 19:05:45.980007 Epoch 1/10, cost: 0.38846520567016235, val_loss: 0.32302421145141125, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:52.437379 Epoch 10/10, cost: 0.15774467611198972, val_loss: 0.259886841988191, train_acc: 0.94 val_acc: 0.93 \n",
            "(42/50)\n",
            "Lr: 0.0011863 Reg: 1.0558142298303257e-05\n",
            "2021-02-15 19:05:53.448645 Epoch 1/10, cost: 0.38207434649300426, val_loss: 0.32878281036391854, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:05:59.868109 Epoch 10/10, cost: 0.14710157594768106, val_loss: 0.2805550917983055, train_acc: 0.94 val_acc: 0.93 \n",
            "(43/50)\n",
            "Lr: 0.0011863 Reg: 1.3803685086375892e-05\n",
            "2021-02-15 19:06:00.803322 Epoch 1/10, cost: 0.39223319510365745, val_loss: 0.3396301227621734, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:06:06.914466 Epoch 10/10, cost: 0.14038735905745228, val_loss: 0.26469667605124414, train_acc: 0.96 val_acc: 0.95 \n",
            "(44/50)\n",
            "Lr: 0.0011863 Reg: 1.1792198478643766e-05\n",
            "2021-02-15 19:06:07.852020 Epoch 1/10, cost: 0.3841478800887515, val_loss: 0.3327360386028886, train_acc: 0.86 val_acc: 0.85 \n",
            "2021-02-15 19:06:14.083440 Epoch 10/10, cost: 0.15424522278225347, val_loss: 0.2918773479759693, train_acc: 0.95 val_acc: 0.94 \n",
            "(45/50)\n",
            "Lr: 0.0011863 Reg: 1.3231716772790006e-05\n",
            "2021-02-15 19:06:15.030183 Epoch 1/10, cost: 0.3911807100484326, val_loss: 0.3382568461820483, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:06:21.221605 Epoch 10/10, cost: 0.1483366818279977, val_loss: 0.2743055857717991, train_acc: 0.95 val_acc: 0.94 \n",
            "(46/50)\n",
            "Lr: 0.0011863 Reg: 1.4787619453573552e-05\n",
            "2021-02-15 19:06:22.204301 Epoch 1/10, cost: 0.3965690910436545, val_loss: 0.33025586791336536, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:06:28.369837 Epoch 10/10, cost: 0.1510446012779406, val_loss: 0.26281114807352424, train_acc: 0.95 val_acc: 0.94 \n",
            "(47/50)\n",
            "Lr: 0.0011863 Reg: 1.1040642849111663e-05\n",
            "2021-02-15 19:06:29.313504 Epoch 1/10, cost: 0.37763513434844415, val_loss: 0.34160505700856447, train_acc: 0.86 val_acc: 0.85 \n",
            "2021-02-15 19:06:35.752454 Epoch 10/10, cost: 0.1446048110296392, val_loss: 0.2649448988959193, train_acc: 0.96 val_acc: 0.95 \n",
            "(48/50)\n",
            "Lr: 0.0011863 Reg: 1.4968533747050963e-05\n",
            "2021-02-15 19:06:36.672067 Epoch 1/10, cost: 0.3812412611997811, val_loss: 0.3306458727456629, train_acc: 0.87 val_acc: 0.86 \n",
            "2021-02-15 19:06:43.208604 Epoch 10/10, cost: 0.1550072465495319, val_loss: 0.28254608530551195, train_acc: 0.95 val_acc: 0.94 \n",
            "(49/50)\n",
            "Lr: 0.0011863 Reg: 1.1579659221975612e-05\n",
            "2021-02-15 19:06:44.138177 Epoch 1/10, cost: 0.37363359445978883, val_loss: 0.34318114584311843, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:06:50.308259 Epoch 10/10, cost: 0.14839157782447565, val_loss: 0.275862080976367, train_acc: 0.95 val_acc: 0.94 \n",
            "(50/50)\n",
            "Lr: 0.0011863 Reg: 1.2517999642004448e-05\n",
            "2021-02-15 19:06:51.221142 Epoch 1/10, cost: 0.3776142492795446, val_loss: 0.32776123145595193, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-15 19:06:57.467026 Epoch 10/10, cost: 0.14364392433766346, val_loss: 0.258640865329653, train_acc: 0.96 val_acc: 0.95 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wua9xzhxFskA"
      },
      "source": [
        "# Hyperparameters:\r\n",
        "reg = 0.000010552\r\n",
        "lr = 0.0011863 "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WonE00MDPp0"
      },
      "source": [
        "# Save file given path to drive's content directory\r\n",
        "def save_dir(path):\r\n",
        "  shutil.copytree(os.listdir(path),os.listdir(\"/content/drive\"))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4H0LfIXcCmb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnYY9j2cEhY"
      },
      "source": [
        "# Call the training routing with static hyperparameters as chosen above\n",
        "# If model is not provided a new model is obj is created\n",
        "def train_model(n_epochs=100, model=None):\n",
        "  # Specifications for training\n",
        "  train_loader = DataLoader(cifar2, batch_size=64, shuffle= True)\n",
        "  val_loader = DataLoader(cifar2_val, batch_size=64, shuffle= False)\n",
        "  \n",
        "  model = model\n",
        "  if model == None:\n",
        "    model = BirdAirplaneClassifier()\n",
        "  else:\n",
        "    model = model.copy()\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  # reg = 0.000010552\n",
        "  # lr = 0.0011863\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
        "    \n",
        "  train(\n",
        "    epochs=n_epochs,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    train_loader = train_loader,\n",
        "    val_loader = val_loader,\n",
        "    print_int = 5,\n",
        "    writer = SummaryWriter(\"runs/Training\")\n",
        "  )\n",
        "  torch.save(model.state_dict(), time.strftime(\"%Y%m%d-%H%M%S\") + '_birds_from_airplanes.pt')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5dXT2EN3g-p",
        "outputId": "d53208e6-196d-45d8-9158-5ecb841b7206"
      },
      "source": [
        "train_model(200)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-20 09:56:42.068331 Epoch 1/200, cost: 0.39295317318029466, val_loss: 0.32455219188705087, train_acc: 0.86 val_acc: 0.86 \n",
            "2021-02-20 09:56:44.999265 Epoch 5/200, cost: 0.23889059730016501, val_loss: 0.275973972864449, train_acc: 0.91 val_acc: 0.91 \n",
            "2021-02-20 09:56:48.565845 Epoch 10/200, cost: 0.14652584633155233, val_loss: 0.26974772615358233, train_acc: 0.96 val_acc: 0.94 \n",
            "2021-02-20 09:56:52.119385 Epoch 15/200, cost: 0.0855239766537194, val_loss: 0.29206226114183664, train_acc: 0.97 val_acc: 0.96 \n",
            "2021-02-20 09:56:55.644905 Epoch 20/200, cost: 0.03861371154902847, val_loss: 0.33976264321245253, train_acc: 0.99 val_acc: 0.98 \n",
            "2021-02-20 09:56:59.201407 Epoch 25/200, cost: 0.03399816056072807, val_loss: 0.3338632481172681, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:02.773781 Epoch 30/200, cost: 0.019587520478815314, val_loss: 0.42801597574725747, train_acc: 0.99 val_acc: 0.97 \n",
            "2021-02-20 09:57:06.347121 Epoch 35/200, cost: 0.011512325209073105, val_loss: 0.4243968967348337, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:09.925933 Epoch 40/200, cost: 0.008449739884069059, val_loss: 0.4752034400589764, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:13.472357 Epoch 45/200, cost: 0.01024791933032595, val_loss: 0.4324751503299922, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:17.025713 Epoch 50/200, cost: 0.0021810993644153804, val_loss: 0.45076837530359626, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:20.576030 Epoch 55/200, cost: 0.0012131038657241281, val_loss: 0.454316396266222, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:24.141532 Epoch 60/200, cost: 0.000844961761257457, val_loss: 0.46878237649798393, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:27.677169 Epoch 65/200, cost: 0.04267752737957676, val_loss: 0.4157571450341493, train_acc: 0.99 val_acc: 0.97 \n",
            "2021-02-20 09:57:31.232853 Epoch 70/200, cost: 0.003573437950983169, val_loss: 0.4337665506172925, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:34.791320 Epoch 75/200, cost: 0.0025345552812781258, val_loss: 0.4598365817219019, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:38.343280 Epoch 80/200, cost: 0.07433716962291936, val_loss: 0.4779671239666641, train_acc: 0.98 val_acc: 0.96 \n",
            "2021-02-20 09:57:41.887022 Epoch 85/200, cost: 0.004565434466052362, val_loss: 0.45976753369905055, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:45.423247 Epoch 90/200, cost: 0.0013652631997113757, val_loss: 0.4602414723485708, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:48.951342 Epoch 95/200, cost: 0.0009717711806964651, val_loss: 0.4727166844531894, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:52.487845 Epoch 100/200, cost: 0.033053661385183314, val_loss: 0.4410813944414258, train_acc: 0.99 val_acc: 0.98 \n",
            "2021-02-20 09:57:56.030519 Epoch 105/200, cost: 0.0017382768885555802, val_loss: 0.47114150994457304, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:57:59.555123 Epoch 110/200, cost: 0.0010663369691086885, val_loss: 0.48851014976389706, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:03.099810 Epoch 115/200, cost: 0.019216358673144845, val_loss: 0.5379598101135343, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:06.772951 Epoch 120/200, cost: 0.0013734969562757464, val_loss: 0.5261665896978229, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:10.374157 Epoch 125/200, cost: 0.0006455108633666791, val_loss: 0.5253487741574645, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:13.933632 Epoch 130/200, cost: 0.07695534897695301, val_loss: 0.6018079714849591, train_acc: 0.97 val_acc: 0.95 \n",
            "2021-02-20 09:58:17.493305 Epoch 135/200, cost: 0.004772178705442092, val_loss: 0.53090546047315, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:21.042005 Epoch 140/200, cost: 0.0007356325106322321, val_loss: 0.5394891877658665, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:24.625438 Epoch 145/200, cost: 0.0020852253680928626, val_loss: 0.5830008261837065, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:28.212579 Epoch 150/200, cost: 0.004656678585262946, val_loss: 0.5140346116386354, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:31.806584 Epoch 155/200, cost: 0.000846141587792129, val_loss: 0.536149465944618, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:35.378126 Epoch 160/200, cost: 0.0007858175536549789, val_loss: 0.5592781885061413, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:38.905619 Epoch 165/200, cost: 0.10964000729434667, val_loss: 0.5580913366284221, train_acc: 0.98 val_acc: 0.96 \n",
            "2021-02-20 09:58:42.440391 Epoch 170/200, cost: 0.001290972789105882, val_loss: 0.5170016197953373, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:45.958163 Epoch 175/200, cost: 0.0006704767857760541, val_loss: 0.5396881098859012, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:49.531197 Epoch 180/200, cost: 0.0018487750068025153, val_loss: 0.5610669597517699, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:53.090465 Epoch 185/200, cost: 0.0002945766575796868, val_loss: 0.5858517698943615, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:58:56.608573 Epoch 190/200, cost: 0.0003215820229603764, val_loss: 0.6015127960126847, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:59:00.157907 Epoch 195/200, cost: 0.010147891714382963, val_loss: 0.5479801911860704, train_acc: 1.00 val_acc: 0.98 \n",
            "2021-02-20 09:59:03.712986 Epoch 200/200, cost: 0.001391790612418335, val_loss: 0.5621788264252245, train_acc: 1.00 val_acc: 0.98 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1XqD6-G1QHA",
        "outputId": "0ac04ecb-aa87-4483-957a-f1bd735e854a"
      },
      "source": [
        "# Test Dataset\r\n",
        "test_dataset = datasets.CIFAR10(data_path,train=False, download= True, transform= transforms.ToTensor())\r\n",
        "label_map = {0: 0, 2: 1}\r\n",
        "cifar2_test = [(img, label_map[label]) for img, label, in test_dataset if label in label_map.keys()]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoVz8ws7trVT"
      },
      "source": [
        "# Evaluation: Get Acuracy of model using the test_dataset of cifar\r\n",
        "def test(path_to_model):\r\n",
        "  model = BirdAirplaneClassifier().to(device)\r\n",
        "  model.load_state_dict(torch.load(path_to_model,map_location=device))\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "  total_entries = len(cifar2_test)\r\n",
        "  correct = 0.0\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for entry in cifar2_test:\r\n",
        "      img = entry[0][None].to(device)\r\n",
        "      label = entry[1]\r\n",
        "\r\n",
        "      #  Calculate accuracy\r\n",
        "      outputs = model(img)\r\n",
        "      _, predicted = torch.max(outputs, dim=1)\r\n",
        "      correct += int((predicted == label).sum())\r\n",
        "\r\n",
        "  print(f\"Accuracy: {correct/total_entries}\")    "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnDffXdzuK0b",
        "outputId": "fe78fe6a-78fd-41be-fba9-57c3a757dff7"
      },
      "source": [
        "test(\"/content/drive/MyDrive/models/20210215-193728_birds_from_airplanes.pt\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI0oB4QDwLI1",
        "outputId": "f10747fc-9656-4658-ac91-7b3d76dbea31"
      },
      "source": [
        "test(\"/content/20210220-095903_birds_from_airplanes.pt\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.896\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}